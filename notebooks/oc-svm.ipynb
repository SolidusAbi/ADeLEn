{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "project_dir = os.path.join(os.getcwd(),'..')\n",
    "if project_dir not in sys.path:\n",
    "    sys.path.append(project_dir)\n",
    "\n",
    "from experiments.MNIST import ExperimentSVM\n",
    "from experiments.utils import generate_roc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "def generate_roc_df(roc_list:list) -> pd.DataFrame:\n",
    "    ''' \n",
    "        Create a DataFrame from a list of roc curves\n",
    "        Args:\n",
    "        -----\n",
    "            roc_list: list\n",
    "                List of N roc curves where N is the number of iterations. It is a \n",
    "                list of tuples of the form (fpr, tpr), where fpr is the false positive\n",
    "                rate and tpr is the true positive rate.\n",
    "        Returns:\n",
    "        --------\n",
    "            roc_df: pd.DataFrame\n",
    "                DataFrame with multiindex\n",
    "    '''\n",
    "    index_names = [\n",
    "        list(map(lambda x: 'It {}'.format(x), np.repeat(np.arange(len(roc_list)), 2) + 1 )),\n",
    "        ['FPR', 'TPR']*len(roc_list)\n",
    "    ]\n",
    "        \n",
    "    tuples = list(zip(*index_names))\n",
    "    index = pd.MultiIndex.from_tuples(tuples)\n",
    "    roc_df = pd.DataFrame(chain.from_iterable(roc_list), index=index)\n",
    "    return roc_df\n",
    "\n",
    "def generate_multi_df(data:list, index_names:list) -> pd.DataFrame:\n",
    "    index_names = [\n",
    "        list(map(lambda x: 'It {}'.format(x), np.repeat(np.arange(len(data)), len(index_names)) + 1 )),\n",
    "        index_names*len(data)\n",
    "    ]\n",
    "\n",
    "    tuples = list(zip(*index_names))\n",
    "    index = pd.MultiIndex.from_tuples(tuples)\n",
    "    return pd.DataFrame(chain.from_iterable(data), index=index)\n",
    "\n",
    "def save_result(roc:list, scores:list, metrics:np.ndarray, config:dict) -> tuple:\n",
    "    '''\n",
    "        Save the results of the experiment\n",
    "        Args:\n",
    "        -----\n",
    "            roc: list\n",
    "                List of roc curves\n",
    "            auc: list\n",
    "                List of AUC scores\n",
    "            config: dict\n",
    "                Configuration of the experiment\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "            roc_df: pd.DataFrame\n",
    "                ROC Cuve dataFrame with multiindex, considering the iterations.\n",
    "            auc_df: pd.DataFrame\n",
    "                DataFrame with the AUC scores\n",
    "    '''\n",
    "\n",
    "    roc_df = generate_multi_df(roc, ['FPR', 'TPR']).T\n",
    "    scores_df = generate_multi_df(scores, ['Normal', 'Anomaly']).T\n",
    "    metrics_df = pd.DataFrame(metrics, columns=['Accuracy', 'Precision', 'Recall', 'F1', 'AUC'])\n",
    "\n",
    "    roc_df.to_pickle(os.path.join(config['save_result_dir'], 'roc.pkl'))\n",
    "    scores_df.to_pickle(os.path.join(config['save_result_dir'], 'sample_score.pkl'))\n",
    "    metrics_df.to_csv(os.path.join(config['save_result_dir'], 'metrics.csv'))\n",
    "    \n",
    "    return roc_df, scores_df, metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exp. pollution=0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [01:37<00:00, 48.99s/It., AUC=0.987]\n"
     ]
    }
   ],
   "source": [
    "n_iter = 2\n",
    "seed = 2*np.arange(n_iter, dtype=int) + 42\n",
    "\n",
    "pollution_exp = [0, .05, .1, .2]\n",
    "pollution_exp = [.1]\n",
    "for pollution in pollution_exp:\n",
    "    print(f'Exp. {pollution=}')\n",
    "    iterator = tqdm(\n",
    "                range(n_iter),\n",
    "                leave=True,\n",
    "                unit=\"It.\",\n",
    "                postfix={\"AUC\": \"%.3f\" % -1},\n",
    "            )\n",
    "\n",
    "    roc, scores = [], []\n",
    "    metrics = np.empty((n_iter, 5)) # acc, prec, rec, f1, auc\n",
    "\n",
    "    for it in iterator:\n",
    "        exp = ExperimentSVM(known_anomalies=.1, pollution=pollution, seed=int(seed[it]))\n",
    "        if it == 0:\n",
    "            config = exp.config()\n",
    "            exp.save_config()\n",
    "        \n",
    "        \n",
    "        auc_score = exp.run(verbose=0)\n",
    "        iterator.set_postfix({\"AUC\": \"%.3f\" % auc_score})\n",
    "\n",
    "        fpr, tpr, roc_auc = exp.roc_curve()\n",
    "        normal_scores, anomaly_scores = exp.score_per_label()\n",
    "        acc, prec, rec, f1 = exp.classification_metrics()\n",
    "        \n",
    "        roc.append((fpr, tpr))   \n",
    "        scores.append((normal_scores, anomaly_scores))\n",
    "        metrics[it] = [acc, prec, rec, f1, roc_auc]\n",
    "        \n",
    "    roc_df, scores_df, metrics_df = save_result(roc, scores, metrics, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">It 1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">It 2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Normal</th>\n",
       "      <th>Anomaly</th>\n",
       "      <th>Normal</th>\n",
       "      <th>Anomaly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56.711340</td>\n",
       "      <td>11.541255</td>\n",
       "      <td>56.906886</td>\n",
       "      <td>12.697677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61.595816</td>\n",
       "      <td>5.313281</td>\n",
       "      <td>62.413564</td>\n",
       "      <td>5.233259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49.188122</td>\n",
       "      <td>5.128848</td>\n",
       "      <td>50.955794</td>\n",
       "      <td>5.849974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48.283112</td>\n",
       "      <td>8.178213</td>\n",
       "      <td>49.701585</td>\n",
       "      <td>5.476550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45.359064</td>\n",
       "      <td>4.552603</td>\n",
       "      <td>47.975413</td>\n",
       "      <td>5.247473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>53.594023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.691954</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131</th>\n",
       "      <td>62.485781</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64.473753</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1132</th>\n",
       "      <td>45.773438</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.863794</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1133</th>\n",
       "      <td>47.395333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.132386</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1134</th>\n",
       "      <td>59.579692</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.643255</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1135 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           It 1                  It 2           \n",
       "         Normal    Anomaly     Normal    Anomaly\n",
       "0     56.711340  11.541255  56.906886  12.697677\n",
       "1     61.595816   5.313281  62.413564   5.233259\n",
       "2     49.188122   5.128848  50.955794   5.849974\n",
       "3     48.283112   8.178213  49.701585   5.476550\n",
       "4     45.359064   4.552603  47.975413   5.247473\n",
       "...         ...        ...        ...        ...\n",
       "1130  53.594023        NaN  56.691954        NaN\n",
       "1131  62.485781        NaN  64.473753        NaN\n",
       "1132  45.773438        NaN  46.863794        NaN\n",
       "1133  47.395333        NaN  49.132386        NaN\n",
       "1134  59.579692        NaN  61.643255        NaN\n",
       "\n",
       "[1135 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_df.to_pickle(os.path.join(config['save_result_dir'], 'roc.pkl'))\n",
    "scores_df.to_pickle(os.path.join(config['save_result_dir'], 'sample_score.pkl'))\n",
    "metrics_df.to_csv(os.path.join(config['save_result_dir'], 'metrics.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "normal = scores_df.iloc[:, 0]\n",
    "anomaly_scores = scores_df.iloc[:, 1]\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.hist(normal, bins=10, alpha=0.5, label='Normal')\n",
    "plt.hist(anomaly_scores, bins=10, alpha=0.5, label='Anomaly')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "normal = scores_df.iloc[:, 2]\n",
    "anomaly_scores = scores_df.iloc[:, 3]\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.hist(normal, bins=10, alpha=0.5, label='Normal')\n",
    "plt.hist(anomaly_scores, bins=10, alpha=0.5, label='Anomaly')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.score_samples(x_test)\n",
    "plt.hist(score, 25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Asumiendo que tienes las puntuaciones de predicción de tu modelo en y_scores\n",
    "fpr, tpr, thresholds = roc_curve(y_test, score)\n",
    "\n",
    "# Calcular la diferencia entre TPR y FPR para cada umbral\n",
    "differences = tpr - fpr\n",
    "\n",
    "# Encontrar el índice del umbral que maximiza la diferencia\n",
    "optimal_threshold_index = np.argmax(differences)\n",
    "\n",
    "# Obtener el umbral óptimo\n",
    "optimal_threshold = thresholds[optimal_threshold_index]\n",
    "\n",
    "print(\"Optimal threshold:\", optimal_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(score[np.argwhere(_y_test==1).squeeze()], bins=10, alpha=.3, label='normal')\n",
    "plt.hist(score[np.argwhere(_y_test==-1).squeeze()], bins=10, alpha=.3, label='anomaly')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import Normalize,ToTensor, Compose\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "## Extract a 2 from the test dataset\n",
    "number = 2\n",
    "transform = Compose([ToTensor(), Normalize((0.5,), (0.5,))])\n",
    "test2_dataset = MNIST('data/', train = False, download = True, transform=transform)\n",
    "test2_idx = torch.where((test2_dataset.targets == number))[0]\n",
    "test2_dataset = Subset(test2_dataset, test2_idx)\n",
    "\n",
    "X, y = zip(*test2_dataset)\n",
    "X = torch.stack(X).reshape(-1, 28*28)\n",
    "y = torch.tensor(y).flatten()\n",
    "y_score = model.score_samples(X)\n",
    "# y_pred = np.zeros_like(y_score, dtype=np.int)\n",
    "# y_pred[y_score > 3] = 1\n",
    "# y_score = model(X).detach()[:,1]\n",
    "\n",
    "plt.hist(y_score, bins=10, alpha=.3, label='normal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_hat = model.predict(X)\n",
    "plt.hist(x_hat, bins=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_score > 1e-2\n",
    "np.unique(y_pred), np.bincount(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Tus datos\n",
    "data1 = score[_y_test==1]\n",
    "data2 = score[_y_test==-1]\n",
    "\n",
    "# Realizar la prueba t\n",
    "t_stat, p_value = stats.ttest_ind(data1, data2)\n",
    "\n",
    "print(f\"t-statistic: {t_stat}\")\n",
    "print(f\"p-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing OC-SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import PredefinedSplit\n",
    "\n",
    "seed = 42\n",
    "exp = ExperimentADeLEn(0, 0.1, seed=seed)\n",
    "x_train, y_train = zip(*[(_x, _y) for _x, _y in exp.train_dataset])\n",
    "x_train, y_train = torch.stack(x_train), torch.tensor(y_train)\n",
    "\n",
    "x_test, y_test = zip(*[(_x, _y) for _x, _y in exp.test_dataset])\n",
    "x_test, y_test = torch.stack(x_test), torch.tensor(y_test)\n",
    "# pick the 10% of the x_test, 5% of the anomalies and 5% of the normal samples\n",
    "percent = .05\n",
    "normal_idx = torch.argwhere(y_test == 0).flatten()\n",
    "n = int(len(normal_idx) * percent)\n",
    "idx = torch.randperm(len(normal_idx))\n",
    "normal_idx = normal_idx[idx[:n]]\n",
    "\n",
    "anomaly_idx = torch.argwhere(y_test == 1).flatten()\n",
    "n = int(len(anomaly_idx) * percent)\n",
    "idx = torch.randperm(len(anomaly_idx))\n",
    "anomaly_idx = anomaly_idx[idx[:n]]\n",
    "\n",
    "idx = torch.cat([normal_idx, anomaly_idx])\n",
    "x_test, y_test = x_test[idx], y_test[idx]\n",
    "\n",
    "\n",
    "# concatenate x_train and x_test\n",
    "X = torch.concat([x_train, x_test], dim=0).reshape(-1, 28*28)\n",
    "y = torch.concat([y_train, y_test], dim=0)\n",
    "y[y == 1] = -1\n",
    "y[y == 0] = 1\n",
    "\n",
    "\n",
    "test_fold = [-1]*len(x_train) + [0]*len(x_test)\n",
    "ps = PredefinedSplit(test_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "param_grid = {'kernel': ['rbf'], 'gamma': np.logspace(-3, 0, 10),\n",
    "                     'nu': [0.1, 0.3, 0.5, 0.9]}\n",
    "\n",
    "grid = GridSearchCV(OneClassSVM(), param_grid, scoring='f1', verbose=3, cv=ps, n_jobs=-1)\n",
    "grid.fit(X, y)\n",
    "best_params = grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "def make_custom_scorer(X):\n",
    "    def score_oc_svm(estimator, X_test):\n",
    "        score = model.score_samples(X)\n",
    "        fpr, tpr, _ = roc_curve(y, score)\n",
    "        return auc(fpr, tpr)\n",
    "    return score_oc_svm\n",
    "\n",
    "custom_scorer = make_scorer(make_custom_scorer(x_test, y_test), greater_is_better=True)\n",
    "\n",
    "param_grid = {'kernel': ['rbf'], 'gamma': np.logspace(-3, 1, 8),\n",
    "                     'nu': [0.01, 0.05, 0.1, 0.5]}\n",
    "\n",
    "grid = GridSearchCV(OneClassSVM(), param_grid, refit=True, verbose=1, scoring=custom_scorer)\n",
    "grid.fit(_x_train)\n",
    "\n",
    "best_params = grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hypopt import GridSearch\n",
    "\n",
    "param_grid = {'kernel': ['rbf'], 'gamma': np.logspace(-3, 1, 8),\n",
    "                     'nu': [0.01, 0.05, 0.1, 0.5]}\n",
    "\n",
    "opt = GridSearch(model = OneClassSVM(), param_grid=param_grid, num_threads=2, parallelize=True)\n",
    "opt.fit(_x_train, y_train, x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randn(100, 2)\n",
    "y = np.random.randn(100, 2)\n",
    "model.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_custom_scorer(model, X, **kwargs):\n",
    "    def score_oc_svm(y_pred):\n",
    "        # Ignorar y_true y y_pred\n",
    "        # Usar model, X y y para calcular la puntuación\n",
    "        y_pred = model.predict(X)\n",
    "        score = 1\n",
    "        return score\n",
    "    return score_oc_svm\n",
    "\n",
    "custom_scorer = make_scorer(make_custom_scorer(model, x_test, y=y_test), greater_is_better=True)\n",
    "\n",
    "param_grid = {'kernel': ['rbf'], 'gamma': np.logspace(-3, 1, 8),\n",
    "                     'nu': [0.01, 0.05, 0.1, 0.5]}\n",
    "\n",
    "grid = GridSearchCV(OneClassSVM(), param_grid, refit=True, verbose=0, scoring='accuracy', n_jobs=1)\n",
    "grid.fit(_x_train)\n",
    "\n",
    "best_params = grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import OneClassSVM\n",
    "import numpy as np\n",
    "\n",
    "def custom_cross_val(X, y, model, param_grid, cv=5):\n",
    "    kf = KFold(n_splits=cv)\n",
    "    best_score = -1\n",
    "    best_params = None\n",
    "\n",
    "    for params in param_grid:\n",
    "        scores = []\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            model.set_params(**params)\n",
    "            model.fit(X_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            score = accuracy_score(y_test, y_pred)\n",
    "            scores.append(score)\n",
    "        avg_score = np.mean(scores)\n",
    "        if avg_score > best_score:\n",
    "            best_score = avg_score\n",
    "            best_params = params\n",
    "    return best_params, best_score\n",
    "\n",
    "model = OneClassSVM()\n",
    "param_grid = [{'kernel': ['rbf'], 'gamma': np.logspace(-3, 1, 8), 'nu': [0.01, 0.05, 0.1, 0.5]}]\n",
    "best_params, best_score = custom_cross_val(_x_train, y_train, model, param_grid, cv=5)\n",
    "\n",
    "print(\"Best parameters:\", best_params)\n",
    "print(\"Best score:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.hist(score, bins=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation using training set for obtaining the best hyperparameters\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': np.logspace(-3, 1, 10),\n",
    "                     'nu': [0.1, 0.2, 0.3, 0.4, 0.5]}]\n",
    "\n",
    "scores = ['roc_auc_ovr']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(\n",
    "        OneClassSVM(), tuned_parameters, scoring=score\n",
    "    )\n",
    "    clf.fit(x_train.numpy())\n",
    "\n",
    "    # print(\"Best parameters set found on development set:\")\n",
    "    # print()\n",
    "    # print(clf.best_params_)\n",
    "    # print()\n",
    "    # print(\"Grid scores on development set:\")\n",
    "    # print()\n",
    "    # means = clf.cv_results_['mean_test_score']\n",
    "    # stds = clf.cv_results_['std_test_score']\n",
    "    # for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    #     print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "    #           % (mean, std * 2, params))\n",
    "    # print()\n",
    "\n",
    "    # print(\"Detailed classification report:\")\n",
    "    # print()\n",
    "    # print(\"The model is trained on the full development set.\")\n",
    "    # print(\"The scores are computed on the full evaluation set.\")\n",
    "    # print()\n",
    "    # y_true, y_pred = y_test, clf.predict(x_test.numpy())\n",
    "    # # print(classification_report(y_true, y_pred))\n",
    "    # # print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "# load the data\n",
    "digits = load_digits()\n",
    "\n",
    "# project the 64-dimensional data to a lower dimension\n",
    "pca = PCA(n_components=15, whiten=False)\n",
    "data = pca.fit_transform(digits.data)\n",
    "\n",
    "# use grid search cross-validation to optimize the bandwidth\n",
    "params = {\"bandwidth\": np.logspace(-1, 1, 20)}\n",
    "grid = GridSearchCV(KernelDensity(), params)\n",
    "grid.fit(data)\n",
    "\n",
    "print(\"best bandwidth: {0}\".format(grid.best_estimator_.bandwidth))\n",
    "\n",
    "# use the best estimator to compute the kernel density estimate\n",
    "kde = grid.best_estimator_\n",
    "\n",
    "# sample 44 new points from the data\n",
    "new_data = kde.sample(44, random_state=0)\n",
    "new_data = pca.inverse_transform(new_data)\n",
    "\n",
    "# turn data into a 4x11 grid\n",
    "new_data = new_data.reshape((4, 11, -1))\n",
    "real_data = digits.data[:44].reshape((4, 11, -1))\n",
    "\n",
    "# plot real digits and resampled digits\n",
    "fig, ax = plt.subplots(9, 11, subplot_kw=dict(xticks=[], yticks=[]))\n",
    "for j in range(11):\n",
    "    ax[4, j].set_visible(False)\n",
    "    for i in range(4):\n",
    "        im = ax[i, j].imshow(\n",
    "            real_data[i, j].reshape((8, 8)), cmap=plt.cm.binary, interpolation=\"nearest\"\n",
    "        )\n",
    "        im.set_clim(0, 16)\n",
    "        im = ax[i + 5, j].imshow(\n",
    "            new_data[i, j].reshape((8, 8)), cmap=plt.cm.binary, interpolation=\"nearest\"\n",
    "        )\n",
    "        im.set_clim(0, 16)\n",
    "\n",
    "ax[0, 5].set_title(\"Selection from the input data\")\n",
    "ax[5, 5].set_title('\"New\" digits drawn from the kernel density model')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = zip(*[(_x, _y) for _x, _y in exp.train_dataset])\n",
    "x_train, y_train = torch.stack(x_train), torch.tensor(y_train)\n",
    "\n",
    "x_train = x_train[y_train==0].view(-1, 28*28).numpy()\n",
    "y_train = y_train[y_train==0].numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomOneCLassSVM(OneClassSVM):\n",
    "    def __init__(self, X_test, y_test, kernel='rbf', gamma='scale',\n",
    "                 nu=0.5, **kwargs):\n",
    "        super().__init__(kernel=kernel, gamma=gamma, nu=nu, **kwargs)\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "    \n",
    "    def score(self, X, y=None):\n",
    "        from sklearn.metrics import roc_curve, auc\n",
    "        score = super().score_samples(self.X_test)\n",
    "        fpr, tpr, _ = roc_curve(self.y_test, score)\n",
    "        return auc(fpr, tpr)\n",
    "    \n",
    "\n",
    "param_grid = {'kernel': ['rbf'], 'gamma': np.logspace(-3, 1, 1),\n",
    "                     'nu': [0.01, 0.05, 0.1, 0.5]}\n",
    "\n",
    "_y_test = y_test.numpy()\n",
    "_y_test[_y_test == 1] = -1\n",
    "_y_test[_y_test == 0] = 1\n",
    "\n",
    "my_scorer = make_scorer(CustomOneCLassSVM.score)\n",
    "grid = GridSearchCV(CustomOneCLassSVM(x_test, y_test), param_grid, refit=True, verbose=2, n_jobs=1)\n",
    "grid.fit(x_train, y_train)\n",
    "\n",
    "best_params = grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = CustomOneCLassSVM(x_test, y_test, **best_params)\n",
    "model = CustomOneCLassSVM(x_test, y_test, kernel='rbf', gamma=.1, nu=1e-3)\n",
    "model.fit(x_train, y_train)\n",
    "model.score(None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MedMNIST Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from torchvision import transforms\n",
    "project_dir = os.path.join(os.getcwd(),'..')\n",
    "if project_dir not in sys.path:\n",
    "    sys.path.append(project_dir)\n",
    "\n",
    "from dataset.medmnist import AnomalyPneumoniaMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import AnomalyPneumoniaMNIST\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision import transforms\n",
    "import random\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[.5], std=[.5]),\n",
    "])\n",
    "\n",
    "# Load the dataset\n",
    "# create a random seed\n",
    "seed = 128\n",
    "train_dataset = AnomalyPneumoniaMNIST('data/', download=True, transform=data_transform, n_normal_samples=-1, known_anomalies=0.2, pollution=0.0, seed=seed)\n",
    "print(train_dataset)\n",
    "\n",
    "train_dataset.montage(5, 5, seed)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = zip(*[(_x, _y) for _x, _y in train_dataset])\n",
    "x_train, y_train = torch.stack(x_train), torch.tensor(y_train)\n",
    "\n",
    "_x_train = x_train[y_train==0].view(-1, 28*28).numpy()\n",
    "_y_train = y_train[y_train==0].numpy()\n",
    "\n",
    "model = OneClassSVM(kernel='rbf', gamma=1e-2, nu=1e-3)\n",
    "model.fit(_x_train)\n",
    "\n",
    "# Predict\n",
    "x_test, y_test = zip(*[(_x, _y) for _x, _y in train_dataset])\n",
    "x_test, y_test = torch.stack(x_test), torch.tensor(y_test)\n",
    "\n",
    "_y_test = y_test.numpy()\n",
    "_y_test[_y_test == 1] = -1\n",
    "_y_test[_y_test == 0] = 1\n",
    "\n",
    "x_test = x_test.reshape(-1, 28*28)\n",
    "_y_pred = model.score_samples(x_test)\n",
    "\n",
    "# Evaluate\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, _ = roc_curve(_y_test, _y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot\n",
    "with plt.style.context((\"seaborn-colorblind\")):\n",
    "    fig = plt.figure(figsize=(6, 4))\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlabel('False Positive Rate', fontsize='x-large')\n",
    "    plt.ylabel('True Positive Rate', fontsize='x-large')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "\n",
    "    plt.tick_params(axis='both', which='major', labelsize='large')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.score_samples(x_test)\n",
    "plt.hist(score, 25)\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Asumiendo que tienes las puntuaciones de predicción de tu modelo en y_scores\n",
    "fpr, tpr, thresholds = roc_curve(y_test, score)\n",
    "auc_score = auc(fpr, tpr)\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(score[torch.argwhere(y_test==1).squeeze()], bins=25, alpha=.5, label='normal')\n",
    "plt.hist(score[torch.argwhere(y_test==-1).squeeze()], bins=25, alpha=.5, label='anomaly')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la diferencia entre TPR y FPR para cada umbral\n",
    "differences = tpr - fpr\n",
    "\n",
    "# Encontrar el índice del umbral que maximiza la diferencia\n",
    "optimal_threshold_index = np.argmax(differences)\n",
    "\n",
    "# Obtener el umbral óptimo\n",
    "optimal_threshold = thresholds[optimal_threshold_index]\n",
    "\n",
    "print(\"Optimal threshold:\", optimal_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Tus datos\n",
    "data1 = score[_y_test==1]\n",
    "data2 = score[_y_test==-1]\n",
    "\n",
    "# Realizar la prueba t\n",
    "t_stat, p_value = stats.ttest_ind(data1, data2)\n",
    "\n",
    "print(f\"t-statistic: {t_stat}\")\n",
    "print(f\"p-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "x_test, y_test = zip(*exp.test_dataset)\n",
    "x_test, y_test = torch.stack(x_test), torch.tensor(y_test)\n",
    "y_test = np.where(y_test.numpy()==0, 1, -1)\n",
    "x_test = x_test.reshape(-1, 28*28)\n",
    "\n",
    "score = exp.model.score_samples(x_test)\n",
    "plt.hist(score[np.argwhere(y_test==1).squeeze()], bins=10, alpha=.3, label='normal', density=False)\n",
    "plt.hist(score[np.argwhere(y_test==-1).squeeze()], bins=10, alpha=.3, label='anomaly', density=False)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = exp.model.predict(x_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import Normalize,ToTensor, Compose\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "## Extract a 2 from the test dataset\n",
    "number = 0\n",
    "transform = Compose([ToTensor(), Normalize((0.5,), (0.5,))])\n",
    "test2_dataset = MNIST('data/', train = False, download = True, transform=transform)\n",
    "test2_idx = torch.where((test2_dataset.targets == number))[0]\n",
    "test2_dataset = Subset(test2_dataset, test2_idx)\n",
    "\n",
    "X, y = zip(*test2_dataset)\n",
    "X = torch.stack(X).reshape(-1, 28*28)\n",
    "y = torch.tensor(y).flatten()\n",
    "y_score = exp.model.score_samples(X)\n",
    "# y_pred = np.zeros_like(y_score, dtype=np.int)\n",
    "# y_pred[y_score > 3] = 1\n",
    "# y_score = model(X).detach()[:,1]\n",
    "\n",
    "plt.hist(y_score, bins=10, alpha=.3, label='normal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_hat = exp.model.predict(X)\n",
    "plt.hist(x_hat, bins=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
