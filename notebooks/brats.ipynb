{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import h5py\n",
    "\n",
    "# Directory containing .h5 files\n",
    "directory = '/media/abian/Extreme SSD/WorkSpace/Dataset/BRATS/archive/BraTS2020_training_data/content/data/'\n",
    "\n",
    "# Create a list of all .h5 files in the directory\n",
    "h5_files = [f for f in os.listdir(directory) if f.endswith('.h5')]\n",
    "print(f\"Found {len(h5_files)} .h5 files:\\nExample file names:{h5_files[:3]}\")\n",
    "\n",
    "# Open the first .h5 file in the list to inspect its contents\n",
    "if h5_files:\n",
    "    file_path = os.path.join(directory, h5_files[25070])\n",
    "    with h5py.File(file_path, 'r') as file:\n",
    "        print(\"\\nKeys for each file:\", list(file.keys()))\n",
    "        for key in file.keys():\n",
    "            print(f\"\\nData type of {key}:\", type(file[key][()]))\n",
    "            print(f\"Shape of {key}:\", file[key].shape)\n",
    "            print(f\"Array dtype: {file[key].dtype}\")\n",
    "            print(f\"Array max val: {np.max(file[key])}\")\n",
    "            print(f\"Array min val: {np.min(file[key])}\")\n",
    "else:\n",
    "    print(\"No .h5 files found in the directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.facecolor'] = '#171717'\n",
    "plt.rcParams['text.color']       = '#DDDDDD'\n",
    "\n",
    "def display_image_channels(image, title='Image Channels'):\n",
    "    channel_names = ['T1-weighted (T1)', 'T1-weighted post contrast (T1c)', 'T2-weighted (T2)', 'Fluid Attenuated Inversion Recovery (FLAIR)']\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(10, 10))\n",
    "    for idx, ax in enumerate(axes.flatten()):\n",
    "        channel_image = image[idx, :, :]  # Transpose the array to display the channel\n",
    "        ax.imshow(channel_image, cmap='magma')\n",
    "        ax.axis('off')\n",
    "        ax.set_title(channel_names[idx])\n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(title, fontsize=20, y=1.03)\n",
    "    plt.show()\n",
    "\n",
    "def display_mask_channels_as_rgb(mask, title='Mask Channels as RGB'):\n",
    "    channel_names = ['Necrotic (NEC)', 'Edema (ED)', 'Tumour (ET)']\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(9.75, 5))\n",
    "    for idx, ax in enumerate(axes):\n",
    "        rgb_mask = np.zeros((mask.shape[1], mask.shape[2], 3), dtype=np.uint8)\n",
    "        rgb_mask[..., idx] = mask[idx, :, :] * 255  # Transpose the array to display the channel\n",
    "        ax.imshow(rgb_mask)\n",
    "        ax.axis('off')\n",
    "        ax.set_title(channel_names[idx])\n",
    "    plt.suptitle(title, fontsize=20, y=0.93)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def overlay_masks_on_image(image, mask, title='Brain MRI with Tumour Masks Overlay'):\n",
    "    t1_image = image[0, :, :]  # Use the first channel of the image\n",
    "    t1_image_normalized = (t1_image - t1_image.min()) / (t1_image.max() - t1_image.min())\n",
    "\n",
    "    rgb_image = np.stack([t1_image_normalized] * 3, axis=-1)\n",
    "    color_mask = np.stack([mask[0, :, :], mask[1, :, :], mask[2, :, :]], axis=-1)\n",
    "    rgb_image = np.where(color_mask, color_mask, rgb_image)\n",
    "    \n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(rgb_image)\n",
    "    plt.title(title, fontsize=18, y=1.02)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "# Sample image to view\n",
    "sample_file_path = os.path.join(directory, h5_files[25070])\n",
    "data = {}\n",
    "with h5py.File(sample_file_path, 'r') as file:\n",
    "    for key in file.keys():\n",
    "        data[key] = file[key][()]\n",
    "\n",
    "# Transpose the image and mask to have channels first\n",
    "image = data['image'].transpose(2, 0, 1)\n",
    "mask = data['mask'].transpose(2, 0, 1)\n",
    "\n",
    "# View images using plotting functions\n",
    "display_image_channels(image)\n",
    "display_mask_channels_as_rgb(mask)\n",
    "overlay_masks_on_image(image, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Since tumors mostly occur in the middle of the brain, we exclude the lowest 80 slices and the uppermost 26 slices.\" Reference: Diffusion Models for Medical Anomaly Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular expression to extract the patient ID from the file name:\n",
    "# filename: volume_{id}_slice_{slice}.h5\n",
    "\n",
    "import re\n",
    "patient_slices = [re.search(r'volume_(\\d+)_slice_(\\d+)', f).groups() for f in h5_files]\n",
    "patient_slices\n",
    "\n",
    "filtered_patient_slices = list(filter(lambda p: 80 <= int(p[1]) < 128, patient_slices))\n",
    "len(filtered_patient_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [f'volume_{p[0]}_slice_{p[1]}.h5' for p in filtered_patient_slices]\n",
    "filenames[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "labels = np.zeros(len(filenames))\n",
    "\n",
    "# Iterate through the files and check if the mask contains tumour\n",
    "for i in tqdm(range(len(filenames))):\n",
    "    sample_file_path = os.path.join(directory, filenames[i])\n",
    "    data = {}\n",
    "    with h5py.File(sample_file_path, 'r') as file:\n",
    "        for key in file.keys():\n",
    "            data[key] = file[key][()]\n",
    "\n",
    "    if len(np.unique(data['mask'])) > 1:\n",
    "        labels[i] = 1\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'Filename': filenames, 'Label': labels.astype(int)})\n",
    "df.to_csv('tumour_labels.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '/media/abian/Extreme SSD/WorkSpace/Dataset/BRATS/archive/'\n",
    "df.to_csv(os.path.join(dataset_path, 'tumour_labels.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_0 = 1209\n",
    "print(filenames[idx_0])\n",
    "sample_file_path = os.path.join(directory, filenames[idx_0])\n",
    "\n",
    "data_0 = {}\n",
    "with h5py.File(sample_file_path, 'r') as file:\n",
    "        for key in file.keys():\n",
    "            data_0[key] = file[key][()]\n",
    "\n",
    "idx_1 = 2512\n",
    "print(filenames[idx_1])\n",
    "sample_file_path = os.path.join(directory, filenames[idx_1])\n",
    "\n",
    "data_1 = {}\n",
    "with h5py.File(sample_file_path, 'r') as file:\n",
    "        for key in file.keys():\n",
    "            data_1[key] = file[key][()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(data_0['image'][:, :, 0].T, cmap='gray')\n",
    "plt.title('Patient 0')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(data_1['image'][:, :, 0].T, cmap='gray')\n",
    "plt.title('Patient 1')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_0['image'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '/media/abian/Extreme SSD/WorkSpace/Dataset/BRATS/archive/'\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv(os.path.join(dataset_path, 'tumor_labels.csv'))\n",
    "filenames = df['Filename'].values\n",
    "\n",
    "no_tumor_filenames = df[df['Label'] == 0]['Filename'].values\n",
    "\n",
    "sample_file_path = os.path.join(directory, no_tumor_filenames[10])\n",
    "data = {}\n",
    "with h5py.File(sample_file_path, 'r') as file:\n",
    "        for key in file.keys():\n",
    "            data[key] = file[key][()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.bincount(df['Label'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return the filenames that has label as 0\n",
    "df[df['Label'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "for i in range(4):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    plt.imshow(data['image'][:, :, i].T, cmap='gray')\n",
    "    plt.title(f'Channel {i}')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class AnoamlyBrainTumor(Dataset):\n",
    "    ''' \n",
    "        BRATS 2020 dataset adapted for anomaly detection. Since tumors mostly occur in the middle of the brain,\n",
    "        it is excluded the lowest 80 slices and the uppermost 26 slices from the dataset.\n",
    "    '''\n",
    "    def __init__(self, dataset_path:str, transform=None) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.dataset_path = os.path.join(dataset_path, 'BraTS2020_training_data/content/data/')\n",
    "        self.transform = transform\n",
    "\n",
    "        self.df = pd.read_csv(os.path.join(dataset_path, 'tumor_labels.csv'))\n",
    "        self.filenames = self.df['Filename'].values\n",
    "        self.labels = self.df['Label'].values\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.filenames)\n",
    "    \n",
    "    def __getitem__(self, idx:int) -> torch.Tensor:\n",
    "        sample_file_path = os.path.join(self.dataset_path, self.filenames[idx])\n",
    "        with h5py.File(sample_file_path, 'r') as file:\n",
    "            data = file['image'][()].astype(np.float32)\n",
    "            file.close()\n",
    "\n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data, self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_brats_tensor(tensor: torch.Tensor) -> torch.Tensor:\n",
    "    tensor = tensor - torch.min(tensor.view(4,-1), dim=1).values.reshape(4,1,1)\n",
    "    return tensor / torch.max(tensor.view(4,-1), dim=1).values.reshape(4,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: normalize_brats_tensor(x)),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "dataset = AnoamlyBrainTumor(dataset_path, transform=transform)\n",
    "# loader = DataLoader(AnoamlyBrainTumor(dataset_path), batch_size=128, shuffle=True)\n",
    "# for data, label in loader:\n",
    "#     print(data.shape, label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "no_tumor_idx = np.where(dataset.labels == 0)[0]\n",
    "tumor_idx = np.where(dataset.labels == 1)[0]\n",
    "\n",
    "# Select a subset of the dataset for test\n",
    "test_set = Subset(dataset, np.concatenate([no_tumor_idx[:100], tumor_idx[:100]]))\n",
    "print(f\"Number of samples in test subset: {len(test_set)}\")\n",
    "\n",
    "train_set = Subset(dataset, np.concatenate([no_tumor_idx[100:], tumor_idx[100:100+512]]))\n",
    "print(f\"Number of samples in training subset: {len(train_set)}\")\n",
    "\n",
    "# Check the distribution of labels in the training set\n",
    "np.bincount([dataset.labels[i] for i in train_set.indices])\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "project_dir = os.path.join(os.getcwd(),'..')\n",
    "if project_dir not in sys.path:\n",
    "    sys.path.append(project_dir)\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from VAE.AnomalyDetector import AnomalyDetector\n",
    "from VAE.utils import SGVBL, cosine_scheduler\n",
    "\n",
    "class VAEModel(nn.Module):\n",
    "    def __init__(self, input_size, latent_space):\n",
    "        super(VAEModel, self).__init__()\n",
    "        conv_out_size = input_size // (2*2*2)\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(4, 16, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.Dropout2d(0.2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, stride=2, padding=1),\n",
    "            nn.Conv2d(16, 32, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Dropout2d(0.2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, stride=2, padding=1),\n",
    "            nn.Conv2d(32, 64, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Dropout2d(0.2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, stride=2, padding=1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64*(conv_out_size**2), 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.botleneck = AnomalyDetector(128, latent_space)\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_space, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            # nn.Dropout(0.1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64*(conv_out_size**2)),\n",
    "            nn.BatchNorm1d(64*(conv_out_size**2)),\n",
    "            # nn.Dropout(0.1),\n",
    "            nn.ReLU(),\n",
    "            nn.Unflatten(1, (64, conv_out_size, conv_out_size)),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(64, 32, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            # nn.Dropout2d(0.1),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(32, 16, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            # nn.Dropout2d(0.1),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(16, 4, 3, stride=1, padding=1),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x:torch.Tensor) -> torch.Tensor:\n",
    "        x = self.encoder(x)\n",
    "        x = self.botleneck(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "model = VAEModel(240, 10)\n",
    "from torch.nn.functional import mse_loss\n",
    "sgvbl = SGVBL(model, len(train_set), mle=mse_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "240 // (2*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "30*30*128\n",
    "\n",
    "x = torch.rand(2,4,240,240)\n",
    "z = model.encoder[:20](x)\n",
    "b = model.botleneck(z)\n",
    "d = model.decoder(b)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "model.train()\n",
    "n_epochs = 100\n",
    "from tqdm import tqdm\n",
    "# kl_weight = 0.02\n",
    "\n",
    "epoch_iterator = tqdm(\n",
    "        range(n_epochs),\n",
    "        leave=True,\n",
    "        unit=\"epoch\",\n",
    "        postfix={\"tls\": \"%.4f\" % -1},\n",
    "    )\n",
    "\n",
    "kl_weight = cosine_scheduler(n_epochs)\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "for epoch in epoch_iterator:\n",
    "    epoch_loss = 0.\n",
    "    # kl_weight = min(kl_weight+0.012, .9)\n",
    "    for x, y in train_loader:\n",
    "        # check if there are a target with 1\n",
    "        # if torch.any(y == 1):\n",
    "            # print(\"Anomaly detected\")\n",
    "            # break\n",
    "        x = x.to(device) # GPU\n",
    "        opt.zero_grad()\n",
    "        x_hat = torch.tanh(model(x))\n",
    "        # loss = sgvbl(x, x_hat, y, kl_weight[epoch])\n",
    "        loss = sgvbl(x, x_hat, y, 1)\n",
    "        epoch_loss += loss.detach().item()\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    \n",
    "    epoch_iterator.set_postfix(tls=\"%.3f\" % (epoch_loss/len(train_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_hat = torch.tanh(model(x))[0,0]\n",
    "\n",
    "plt.imshow(x_hat.cpu().detach().numpy(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def plot_reconstructed(autoencoder, r0=(-10, 10), r1=(-10, 10), n=12):\n",
    "    w = 240\n",
    "    img = np.zeros((n*w, n*w))\n",
    "    for i, y in enumerate(np.linspace(*r1, n)):\n",
    "        for j, x in enumerate(np.linspace(*r0, n)):\n",
    "            z = torch.Tensor([[x, y]]).to(device)\n",
    "            x_hat = torch.tanh(autoencoder.decoder(z))\n",
    "            x_hat = x_hat.reshape(4, 240, 240)[1].to('cpu').detach().numpy()\n",
    "            img[(n-1-i)*w:(n-1-i+1)*w, j*w:(j+1)*w] = x_hat\n",
    "    \n",
    "    plt.xlabel('$\\mathcal{N}(0, \\sigma_1)$', fontsize='x-large')\n",
    "    plt.ylabel('$\\mathcal{N}(0, \\sigma_2)$', fontsize='x-large')\n",
    "    plt.imshow(img, extent=[*r0, *r1], cmap='viridis')\n",
    "\n",
    "model.eval()\n",
    "plot_reconstructed(model, r0=(-6, 6), r1=(-6, 6), n=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = dataset[0]\n",
    "model.encoder[0:11](x.unsqueeze(0).to(device)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_0 = dataset[no_tumor_idx[0]][0].unsqueeze(0).to(device)\n",
    "x_1 = dataset[tumor_idx[0]][0].unsqueeze(0).to(device)\n",
    "\n",
    "x = torch.vstack([x_0, x_1])\n",
    "x_hat = torch.tanh(model(x))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.imshow(x[0,0].cpu().detach().numpy(), cmap='gray')\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.imshow(x_hat[0,0].cpu().detach().numpy(), cmap='gray')\n",
    "plt.title('Reconstructed Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.imshow(x[1,0].cpu().detach().numpy(), cmap='gray')\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.imshow(x_hat[1,0].cpu().detach().numpy(), cmap='gray')\n",
    "plt.title('Reconstructed Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "model.botleneck.mu, model.botleneck.sigma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "240//2//2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
