{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from torch import nn\n",
    "from torchvision.transforms import Normalize,ToTensor, Compose\n",
    "\n",
    "project_dir = os.path.join(os.getcwd(),'..')\n",
    "if project_dir not in sys.path:\n",
    "    sys.path.append(project_dir)\n",
    "\n",
    "from dataset import AnomalyMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "transform = Compose([ToTensor(), Normalize((0.5,), (0.5,))])\n",
    "\n",
    "dataset = AnomalyMNIST('data/', download=True, transform=transform, n_normal_samples=2000, known_anomalies=0.2, pollution=0.2, seed=seed)\n",
    "print(dataset)\n",
    "\n",
    "dataset.montage(5, 5, seed)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, 1, 1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Dropout2d(0.5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, stride=2, padding=1),\n",
    "            nn.Conv2d(32, 48, 3, 1, 1),\n",
    "            nn.BatchNorm2d(48),\n",
    "            nn.Dropout2d(0.5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, stride=2, padding=1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(48*7*7, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            # nn.Dropout(0.5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _weights(dataset):\n",
    "    _, y = zip(*dataset)\n",
    "    y = torch.tensor(y)\n",
    "\n",
    "    count = torch.bincount(y)\n",
    "    weights = 1. / np.array(count)\n",
    "    weights /= weights.sum()\n",
    "\n",
    "    return weights[y]\n",
    "\n",
    "def train(model, dataset, batch_size, n_epochs, lr=1e-3):\n",
    "    from tqdm import tqdm\n",
    "    from torch.utils.data import DataLoader\n",
    "    from torch.optim import Adam\n",
    "    from torch.nn.functional import one_hot\n",
    "    \n",
    "    # sampler = torch.utils.data.WeightedRandomSampler(_weights(dataset), len(dataset), replacement=True)\n",
    "    # train_loader = DataLoader(dataset, batch_size=batch_size, sampler=sampler)\n",
    "    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    epoch_iterator = tqdm(\n",
    "            range(n_epochs),\n",
    "            leave=True,\n",
    "            unit=\"epoch\",\n",
    "            postfix={\"tls\": \"%.4f\" % -1},\n",
    "        )\n",
    "    \n",
    "    opt = Adam(model.parameters(), lr=lr)\n",
    "    ce = nn.CrossEntropyLoss()\n",
    "    for _ in epoch_iterator:\n",
    "        epoch_loss = 0.\n",
    "        for x, y in train_loader:\n",
    "            # y = one_hot(y, 2).to(device)\n",
    "            y = y.to(device)\n",
    "            x = x.to(device) \n",
    "            opt.zero_grad()\n",
    "            y_hat = model(x)\n",
    "            loss = ce(y_hat, y)\n",
    "            epoch_loss += loss.detach().item()\n",
    "\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "        epoch_iterator.set_postfix(tls=\"%.3f\" % (epoch_loss/len(train_loader)))\n",
    "\n",
    "    return model.eval().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "model = train(model, dataset, 128, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Include the test set configuration in the AnoamlyMNIST class\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "\n",
    "test_dataset_full = MNIST('data/', train = False, download = True, transform = transform)\n",
    "normal_idx = torch.where((test_dataset_full.targets == 1))[0]\n",
    "anomaly_idx = torch.where((test_dataset_full.targets == 7))[0]\n",
    "idx = torch.cat([normal_idx[:1024], anomaly_idx[:1024]]) # 512 samples!\n",
    "\n",
    "test_dataset_full.targets = torch.ones_like(test_dataset_full.targets) * -1\n",
    "test_dataset_full.targets[normal_idx] = 0\n",
    "test_dataset_full.targets[anomaly_idx] = 1\n",
    "\n",
    "x_test_set = Subset(test_dataset_full, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test = zip(*x_test_set)\n",
    "x_test = torch.stack(x_test)\n",
    "y_test = torch.tensor(y_test)\n",
    "\n",
    "y_score = model(x_test).detach().numpy()[:,1]\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_test, y_score[:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "fpr, tpr, _ = roc_curve(y_test, y_score[:])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.hist(y_score[y_test==0], bins=15, alpha=0.5, label='Normal')\n",
    "plt.hist(y_score[y_test==1], bins=15, alpha=0.5, label='Anomaly')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred = model(x_test).detach().argmax(dim=1)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract a 2 from the test dataset\n",
    "number = 3\n",
    "test2_dataset = MNIST('data/', train = False, download = True, transform=transform)\n",
    "test2_idx = torch.where((test2_dataset.targets == number))[0]\n",
    "test2_dataset = Subset(test2_dataset, test2_idx)\n",
    "\n",
    "X, y = zip(*test2_dataset)\n",
    "X = torch.stack(X)\n",
    "y = torch.tensor(y).flatten()\n",
    "y_pred = model(X).detach().argmax(dim=1)\n",
    "y_score = model(X).detach()[:,1]\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(X[0,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1,2,1)\n",
    "plt.hist(y_pred)\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(y_score)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_y = torch.ones_like(y)\n",
    "np.bincount(y_pred == _y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MedMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import medmnist, torch\n",
    "from medmnist import INFO, Evaluator\n",
    "from medmnist.dataset import PneumoniaMNIST\n",
    "import torch.utils.data as data\n",
    "\n",
    "import os, sys\n",
    "project_dir = os.path.join(os.getcwd(),'..')\n",
    "if project_dir not in sys.path:\n",
    "    sys.path.append(project_dir)\n",
    "\n",
    "\n",
    "print(f\"MedMNIST v{medmnist.__version__} @ {medmnist.HOMEPAGE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import AnomalyPneumoniaMNIST\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision import transforms\n",
    "\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[.5], std=[.5]),\n",
    "])\n",
    "\n",
    "# Load the dataset\n",
    "seed = 42\n",
    "train_dataset = AnomalyPneumoniaMNIST('data/', download=True, transform=data_transform, n_normal_samples=-1, known_anomalies=0.15, pollution=0.0, seed=seed)\n",
    "print(train_dataset)\n",
    "\n",
    "train_dataset.montage(5, 5, seed)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "test_dataset = PneumoniaMNIST(split='test', transform=data_transform, download=True, root='data/')\n",
    "\n",
    "train_loader = data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = data.DataLoader(dataset=test_dataset, batch_size=4*BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "model = train(model, train_dataset, 128, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test = zip(*test_dataset)\n",
    "x_test = torch.stack(x_test)\n",
    "y_test = torch.tensor(y_test).flatten()\n",
    "\n",
    "# y_score = model(x_test).detach().numpy().mean(axis=1)\n",
    "y_score = model(x_test).detach().numpy()[:,1]\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_test, y_score[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score.shape\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "fpr, tpr, _ = roc_curve(y_test, y_score[:])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.hist(y_score[y_test==0], bins=15, alpha=0.5, label='Normal')\n",
    "plt.hist(y_score[y_test==1], bins=15, alpha=0.5, label='Anomaly')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Tus datos\n",
    "data1 = y_score[y_test==0]\n",
    "data2 = y_score[y_test==1]\n",
    "\n",
    "# Realizar la prueba t\n",
    "t_stat, p_value = stats.ttest_ind(data1, data2)\n",
    "\n",
    "print(f\"t-statistic: {t_stat}\")\n",
    "print(f\"p-value: {p_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model(x_test).argmax(dim=1)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_hat, target_names=('Normal', 'Anomaly')))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.bincount(y_test), np.bincount(y_hat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
