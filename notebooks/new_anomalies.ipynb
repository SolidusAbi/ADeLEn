{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "project_dir = os.path.join(os.getcwd(),'..')\n",
    "if project_dir not in sys.path:\n",
    "    sys.path.append(project_dir)\n",
    "\n",
    "from ADeLEn.model import ADeLEn\n",
    "from dataset import AnomalyMNIST\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from torch.nn.functional import mse_loss\n",
    "from torchvision.transforms import Normalize,ToTensor, Compose\n",
    "from VAE.loss import SGVBL\n",
    "\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is used to evaluate how affect the use of new anomalies in the proposed ADeLEn method and the supervised DNN. This test has been carried out using the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "transform = Compose([ToTensor(), Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# dataset = AnomalyMNIST('data/', download=True, transform=transform, n_known_anomalies=512, pollution=0.25, seed=seed)\n",
    "dataset = AnomalyMNIST('data/', download=True, transform=transform, n_normal_samples=2000, known_anomalies=0.1, pollution=0.1, seed=seed)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Include the test set configuration in the AnoamlyMNIST class\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "\n",
    "test_dataset = MNIST('data/', train = False, download = True, transform=transform)\n",
    "normal_idx = torch.where((test_dataset.targets == 1))[0]\n",
    "non_observed_anomaly_idx = torch.where((test_dataset.targets == 9))[0]\n",
    "test_dataset = Subset(test_dataset, torch.cat([normal_idx, non_observed_anomaly_idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADeLEn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _weights(dataset):\n",
    "    import numpy as np\n",
    "    _, y = zip(*dataset)\n",
    "    y = torch.tensor(y)\n",
    "\n",
    "    count = torch.bincount(y)\n",
    "    weights = 1. / np.array(count)\n",
    "    weights /= weights.sum()\n",
    "\n",
    "    return weights[y]\n",
    "\n",
    "def adelen_train(model, dataset, batch_size, n_epochs, lr=1e-3, kl_weight=1, weighted_sampler=False):\n",
    "    from tqdm import tqdm\n",
    "    from torch.utils.data import DataLoader\n",
    "    from torch.optim import Adam\n",
    "    \n",
    "    if weighted_sampler:\n",
    "        sampler = torch.utils.data.WeightedRandomSampler(_weights(dataset), len(dataset), replacement=True)\n",
    "        train_loader = DataLoader(dataset, batch_size=batch_size, sampler=sampler)\n",
    "    else:\n",
    "        train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    epoch_iterator = tqdm(\n",
    "            range(n_epochs),\n",
    "            leave=True,\n",
    "            unit=\"epoch\",\n",
    "            postfix={\"tls\": \"%.4f\" % -1},\n",
    "        )\n",
    "    \n",
    "    opt = Adam(model.parameters(), lr=lr)\n",
    "    sgvbl = SGVBL(model, len(dataset), mle=mse_loss)\n",
    "\n",
    "    for _ in epoch_iterator:\n",
    "        epoch_loss = 0.\n",
    "        for x, y in train_loader:\n",
    "            x = x.to(device) \n",
    "            opt.zero_grad()\n",
    "            x_hat = torch.tanh(model(x))\n",
    "            loss = sgvbl(x, x_hat, y, kl_weight)\n",
    "            epoch_loss += loss.detach().item()\n",
    "\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "        epoch_iterator.set_postfix(tls=\"%.3f\" % (epoch_loss/len(train_loader)))\n",
    "\n",
    "    return model.eval().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 2\n",
    "adelen_model = ADeLEn((28, 28), [1, 32, 48], [1024, 256, 32], bottleneck=d, skip_connection=False)\n",
    "model = adelen_train(adelen_model, dataset, 128, 100, 1e-3, 1, weighted_sampler=False)\n",
    "\n",
    "y, scores = model.score_samples()\n",
    "(scores[y == 0], scores[y == 1])\n",
    "fpr, tpr, _ = roc_curve(y, scores)\n",
    "roc_auc = auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def adelen_threshold(sigma, d)->float:\n",
    "        score = d * np.log(sigma)\n",
    "        gauss = d * np.log(2*torch.pi*torch.e)\n",
    "        return .5 * (gauss + score)\n",
    "\n",
    "def testing(test_dataset, model):\n",
    "    x, y = zip(*test_dataset)\n",
    "    x = torch.stack(x)\n",
    "    y = torch.tensor(y)\n",
    "    y[y == 1] = 0\n",
    "    y[y == 9] = 1\n",
    "\n",
    "    model.eval()\n",
    "    _ = model(x)\n",
    "    y_score = model.score_samples(x)\n",
    "    fpr, tpr, _ = roc_curve(y, y_score)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    y_pred = np.where(y_score > adelen_threshold(1.2, d), 1, 0)\n",
    "\n",
    "\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    precision = precision_score(y, y_pred)\n",
    "    recall = recall_score(y, y_pred)\n",
    "    f1 = f1_score(y, y_pred)\n",
    "    return (accuracy, precision, recall, f1, roc_auc)    \n",
    "\n",
    "def scores(test_dataset, model):\n",
    "    x, y = zip(*test_dataset)\n",
    "    x = torch.stack(x)\n",
    "    y = torch.tensor(y)\n",
    "    y[y == 1] = 0\n",
    "    y[y == 9] = 1\n",
    "\n",
    "    model.eval()\n",
    "    _ = model(x)\n",
    "    y_score = model.score_samples(x)\n",
    "    return (y_score[y == 0], y_score[y == 1])\n",
    "\n",
    "accuracy, precision, recall, f1, roc_auc = testing(test_dataset, model)\n",
    "normal_scores, anomaly_scores = scores(test_dataset, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, precision, recall, f1, roc_auc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_scores.mean(), anomaly_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = zip(*test_dataset)\n",
    "x = torch.stack(x)\n",
    "y = torch.tensor(y)\n",
    "y[y == 1] = 0\n",
    "y[y == 9] = 1\n",
    "\n",
    "model.eval()\n",
    "_ = model(x)\n",
    "y_score = model.score_samples(x)\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "fpr, tpr, _ = roc_curve(y, y_score)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "roc_auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_score[y==0], bins=15, alpha=0.5, label='Normal')\n",
    "plt.hist(y_score[y==1], bins=15, alpha=0.5, label='Anomaly')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the anomalies with lowest score and the highest score\n",
    "# lowest\n",
    "anomalies = x[y == 1]\n",
    "anomalies_score = y_score[y == 1]\n",
    "idx = anomalies_score.argsort()\n",
    "\n",
    "fig, ax = plt.subplots(1, 5, figsize=(15, 3))\n",
    "for i in range(5):\n",
    "    ax[i].imshow(anomalies[idx[i]].squeeze(), cmap='gray')\n",
    "    ax[i].axis('off')\n",
    "    # indicate the score\n",
    "    ax[i].set_title('%.2f' % anomalies_score[idx[i]])\n",
    "plt.show()\n",
    "\n",
    "print('Anomalies with highest score')\n",
    "fig, ax = plt.subplots(1, 5, figsize=(15, 3))\n",
    "for i in range(5):\n",
    "    ax[i].imshow(anomalies[idx[-(i+1)]].squeeze(), cmap='gray')\n",
    "    ax[i].axis('off')\n",
    "    # indicate the score\n",
    "    ax[i].set_title('%.2f' % anomalies_score[idx[-(i+1)]])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments.utils.Supervised import SupervisedModel, train\n",
    "\n",
    "supervised_model = SupervisedModel((28,28), [1, 32, 48], [1024, 256, 32, 2])\n",
    "supervised_model = train(supervised_model, dataset, 128, 100, weighted_sampler=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = zip(*test_dataset)\n",
    "x = torch.stack(x)\n",
    "y = torch.tensor(y)\n",
    "y[y == 1] = 0\n",
    "y[y == 9] = 1\n",
    "\n",
    "supervised_model.eval()\n",
    "_ = supervised_model(x)\n",
    "y_score = supervised_model.score_samples(x)\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "fpr, tpr, _ = roc_curve(y, y_score)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_score[y==0], bins=2, alpha=0.5, label='Normal')\n",
    "plt.hist(y_score[y==1], bins=15, alpha=0.5, label='Anomaly')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the anomalies with lowest score and the highest score\n",
    "# lowest\n",
    "anomalies = x[y == 1]\n",
    "anomalies_score = y_score[y == 1]\n",
    "idx = anomalies_score.argsort()\n",
    "\n",
    "fig, ax = plt.subplots(1, 5, figsize=(15, 3))\n",
    "for i in range(5):\n",
    "    ax[i].imshow(anomalies[idx[i]].squeeze(), cmap='gray')\n",
    "    ax[i].axis('off')\n",
    "    # indicate the score\n",
    "    ax[i].set_title('%.2f' % anomalies_score[idx[i]])\n",
    "plt.show()\n",
    "\n",
    "print('Anomalies with highest score')\n",
    "fig, ax = plt.subplots(1, 5, figsize=(15, 3))\n",
    "for i in range(5):\n",
    "    ax[i].imshow(anomalies[idx[-(i+1)]].squeeze(), cmap='gray')\n",
    "    ax[i].axis('off')\n",
    "    # indicate the score\n",
    "    ax[i].set_title('%.2f' % anomalies_score[idx[-(i+1)]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
