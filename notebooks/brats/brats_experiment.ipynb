{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "project_dir = os.path.join(os.getcwd(),'../..')\n",
    "if project_dir not in sys.path:\n",
    "    sys.path.append(project_dir)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import config\n",
    "import h5py\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "data_directory = os.path.join(config.BRATS_DATASET_PATH, 'BraTS2020_training_data/content/data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(config.BRATS_DATASET_PATH, 'tumour_labels.csv'))\n",
    "filenames = df['Filename'].values\n",
    "\n",
    "no_tumor_filenames = df[df['Label'] == 0]['Filename'].values\n",
    "\n",
    "sample_file_path = os.path.join(data_directory, no_tumor_filenames[10])\n",
    "data = {}\n",
    "with h5py.File(sample_file_path, 'r') as file:\n",
    "        for key in file.keys():\n",
    "            data[key] = file[key][()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(4):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    plt.imshow(data['image'][:, :, i].T, cmap='gray')\n",
    "    plt.title(f'Channel {i}')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class AnomalyBrainTumor(Dataset):\n",
    "    ''' \n",
    "        BRATS 2020 dataset adapted for anomaly detection. Since tumors mostly occur in the middle of the brain,\n",
    "        it is excluded the lowest 80 slices and the uppermost 26 slices from the dataset.\n",
    "    '''\n",
    "    def __init__(self, dataset_path:str, transform=None, on_memory=False) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.on_memory = on_memory\n",
    "        self.dataset_path = os.path.join(dataset_path, 'BraTS2020_training_data/content/data/')\n",
    "        self.transform = transform\n",
    "\n",
    "        self.df = pd.read_csv(os.path.join(dataset_path, 'tumour_labels.csv'))\n",
    "        self.filenames = list(map(lambda x: os.path.join(self.dataset_path, x), self.df['Filename'].values))\n",
    "        self.labels = self.df['Label'].values\n",
    "\n",
    "        if self.on_memory:\n",
    "            self.data = self.__loaddata__(self.filenames)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.filenames)\n",
    "    \n",
    "    def __getitem__(self, idx:int) -> torch.Tensor:\n",
    "        if self.on_memory: \n",
    "            data = self.data[idx]\n",
    "        else:\n",
    "            data = self.__readfile__(self.filenames[idx])\n",
    "\n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data, self.labels[idx]\n",
    "\n",
    "    def __loaddata__(self, filenames:list) -> np.ndarray:\n",
    "        shape = (len(filenames), 240, 240, 4) # BRATS 2020 dataset shape\n",
    "        dataset = np.zeros(shape, dtype=np.float32)\n",
    "        for idx, filename in enumerate(filenames):\n",
    "            with h5py.File(filename, 'r') as file:\n",
    "                dataset[idx] = file['image'][()].astype(np.float32)\n",
    "                file.close()\n",
    "\n",
    "        return dataset\n",
    "\n",
    "    def __readfile__(self, filename:str)-> np.ndarray:\n",
    "        with h5py.File(filename, 'r') as file:\n",
    "            data = file['image'][()].astype(np.float32)\n",
    "            file.close()\n",
    "        \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_brats_tensor(tensor: torch.Tensor) -> torch.Tensor:\n",
    "    tensor = tensor - torch.min(tensor.view(4,-1), dim=1).values.reshape(4,1,1)\n",
    "    return tensor / torch.max(tensor.view(4,-1), dim=1).values.reshape(4,1,1)\n",
    "\n",
    "from torchvision import transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: normalize_brats_tensor(x)),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "dataset = AnomalyBrainTumor(config.BRATS_DATASET_PATH, transform=transform, on_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "\n",
    "def generate_dataset(dataset:Dataset, percent_normal_samples=.75, percent_anomalies=.1) -> (Subset, Subset):\n",
    "    '''\n",
    "        Generate a dataset with a given percentage of normal samples and anomalies. The percentage\n",
    "        of anomalies samples is calculated based on the percentage of normal samples.\n",
    "    \n",
    "    '''\n",
    "    normal_samples = np.where(dataset.labels == 0, 1, 0).astype(bool)\n",
    "\n",
    "    normal_idx = np.argwhere(normal_samples==True).flatten()\n",
    "    anomaly_idx = np.argwhere(normal_samples==False).flatten()\n",
    "\n",
    "    #random selection of samples\n",
    "    normal_selected = np.random.permutation(normal_idx)[:int(len(normal_idx) * percent_normal_samples)]\n",
    "    anomaly_selected = np.random.permutation(anomaly_idx)[:int(len(normal_selected) * percent_anomalies)]\n",
    "\n",
    "    training_subset = np.zeros(len(dataset), dtype=bool)\n",
    "    training_subset[np.concatenate([normal_selected, anomaly_selected])] = True\n",
    "\n",
    "    train_dataset = Subset(dataset, np.argwhere(training_subset).flatten())\n",
    "    test_dataset = Subset(dataset, np.argwhere(~training_subset).flatten())\n",
    "\n",
    "    return train_dataset, test_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = generate_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ADeLEn.model import ADeLEn\n",
    "from torch.nn.functional import mse_loss\n",
    "from VAE.loss import SGVBL\n",
    "from experiments.utils.ADeLEn import train\n",
    "d = 10\n",
    "model = ADeLEn((240, 240), [4, 8, 24, 32, 48], [1024, 128, 32], bottleneck=d, skip_connection=False)\n",
    "sgvbl = SGVBL(model, len(dataset), mle=mse_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import generate_multi_df, generate_roc_df\n",
    "\n",
    "def threshold(sigma, d) -> float:\n",
    "        score = d * np.log(sigma)\n",
    "        gauss = d * np.log(2*torch.pi*torch.e)\n",
    "        return .5 * (gauss + score)\n",
    "\n",
    "def roc_curve(model, test_dataset):\n",
    "    '''\n",
    "        Obtain the ROC curve of the model with the test dataset.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "            fpr: float\n",
    "                False positive rate.\n",
    "            tpr: float\n",
    "                True positive rate.\n",
    "            roc_auc: float\n",
    "                Area under the curve.\n",
    "    '''\n",
    "    from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "    X, y = zip(*test_dataset)\n",
    "    X = torch.stack(X)\n",
    "    y = torch.tensor(y).flatten()\n",
    "\n",
    "    scores = model.score_samples(X)\n",
    "    fpr, tpr, _ = roc_curve(y, scores)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    return (fpr, tpr, roc_auc)\n",
    "\n",
    "def classification_metrics(model, test_dataset, sigma=1.2, d=10) -> tuple:\n",
    "    '''\n",
    "        Test the model with the test dataset\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "            accuracy: float\n",
    "                The accuracy of the model.\n",
    "            precision: float\n",
    "                The precision of the model.\n",
    "            recall: float\n",
    "                The recall of the model.\n",
    "            f1: float\n",
    "                The f1 score of the model.\n",
    "    '''\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "    X, y = zip(*test_dataset)\n",
    "    X = torch.stack(X)\n",
    "    y = torch.tensor(y).flatten()\n",
    "\n",
    "    scores = model.score_samples(X)\n",
    "\n",
    "    y_pred = np.where(scores > threshold(sigma, d), 1, 0)\n",
    "    \n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    precision = precision_score(y, y_pred)\n",
    "    recall = recall_score(y, y_pred)\n",
    "    f1 = f1_score(y, y_pred)\n",
    "    return (accuracy, precision, recall, f1)\n",
    "\n",
    "def score_per_label(model, test_dataset):\n",
    "    X, y = zip(*test_dataset)\n",
    "    X = torch.stack(X)\n",
    "    y = torch.tensor(y).flatten()\n",
    "\n",
    "    scores = model.score_samples(X)\n",
    "    return (scores[y == 0], scores[y == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 25\n",
    "roc, scores = [], []\n",
    "metrics = np.empty((n_iter, 5)) # acc, prec, rec, f1, auc\n",
    "\n",
    "for i in range(n_iter):\n",
    "    train_dataset, test_dataset = generate_dataset(dataset)\n",
    "    model = train(model, train_dataset, 100, 1)\n",
    "    fpr, tpr, roc_auc = roc_curve(model, test_dataset)\n",
    "    acc, prec, rec, f1 = classification_metrics(model, test_dataset, sigma=1.2, d=d)\n",
    "    \n",
    "    roc.append((fpr, tpr))\n",
    "    scores.append(roc_auc)\n",
    "    metrics[i] = [acc, prec, rec, f1, roc_auc]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
